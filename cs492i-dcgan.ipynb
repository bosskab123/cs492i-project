{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-12-18T16:58:00.612466Z","iopub.status.busy":"2021-12-18T16:58:00.611967Z","iopub.status.idle":"2021-12-18T16:58:03.504785Z","shell.execute_reply":"2021-12-18T16:58:03.50392Z","shell.execute_reply.started":"2021-12-18T16:58:00.612379Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tqdm import tqdm \n","import numpy as np\n","import os\n","import re\n","from easydict import EasyDict as edict\n","from PIL import Image\n","from skimage import io, transform\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch import Tensor\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:03.506787Z","iopub.status.busy":"2021-12-18T16:58:03.506545Z","iopub.status.idle":"2021-12-18T16:58:03.549159Z","shell.execute_reply":"2021-12-18T16:58:03.547629Z","shell.execute_reply.started":"2021-12-18T16:58:03.506751Z"},"trusted":true},"outputs":[],"source":["# Define datapath\n","mask_path = '../input/face-mask-lite-dataset/with_mask'\n","face_path = '../input/face-mask-lite-dataset/without_mask'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:03.556172Z","iopub.status.busy":"2021-12-18T16:58:03.555632Z","iopub.status.idle":"2021-12-18T16:58:03.5627Z","shell.execute_reply":"2021-12-18T16:58:03.561849Z","shell.execute_reply.started":"2021-12-18T16:58:03.556132Z"},"trusted":true},"outputs":[],"source":["# Setting hyperparameters\n","args = edict()\n","args.EPOCHS = 10\n","args.BATCH_SIZE=50\n","args.LR = 0.0002\n","args.B1 = 0.5\n","args.B2 = 0.999\n","args.N_CPU = 9\n","args.LATENT_DIM = 100\n","args.IMG_SIZE = 256\n","args.CHANNELS = 3\n","args.NUM_IMG = 10000\n","args.TRAINING_SIZE = int(0.9*args.NUM_IMG)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:03.574699Z","iopub.status.busy":"2021-12-18T16:58:03.574076Z","iopub.status.idle":"2021-12-18T16:58:03.592786Z","shell.execute_reply":"2021-12-18T16:58:03.592085Z","shell.execute_reply.started":"2021-12-18T16:58:03.574662Z"},"trusted":true},"outputs":[],"source":["class FaceTrainDataset(Dataset):\n","    def __init__(self, face_path, mask_path):\n","\n","        def sorted_alphanumeric(data):  \n","            convert = lambda text: int(text) if text.isdigit() else text.lower()\n","            alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","            return sorted(data,key = alphanum_key)\n","        \n","        self.transforms = transforms.Compose(\n","                            [transforms.Resize([args.IMG_SIZE, args.IMG_SIZE]),\n","                             transforms.ToTensor(),])\n","        \n","        self.face_path = face_path\n","        self.mask_path = mask_path\n","        self.face_file = sorted_alphanumeric(os.listdir(face_path))[:args.TRAINING_SIZE]\n","        self.mask_file = sorted_alphanumeric(os.listdir(mask_path))[:args.TRAINING_SIZE]\n","\n","    def __len__(self):\n","        return len(self.face_file)\n","\n","    def __getitem__(self, idx):\n","        face_image = Image.open(self.face_path + '/' + self.face_file[idx])\n","        mask_image = Image.open(self.mask_path + '/' + self.mask_file[idx])\n","        face_image = self.transforms(face_image)\n","        mask_image = self.transforms(mask_image)\n","\n","        return (face_image,mask_image)\n","\n","class FaceTestDataset(Dataset):\n","    def __init__(self, face_path, mask_path):\n","\n","        def sorted_alphanumeric(data):  \n","            convert = lambda text: int(text) if text.isdigit() else text.lower()\n","            alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","            return sorted(data,key = alphanum_key)\n","        \n","        self.transforms = transforms.Compose(\n","                            [transforms.Resize([args.IMG_SIZE, args.IMG_SIZE]),\n","                             transforms.ToTensor(),])\n","        \n","        self.face_path = face_path\n","        self.mask_path = mask_path\n","        self.face_file = sorted_alphanumeric(os.listdir(face_path))[args.TRAINING_SIZE:]\n","        self.mask_file = sorted_alphanumeric(os.listdir(mask_path))[args.TRAINING_SIZE:]\n","\n","    def __len__(self):\n","        return len(self.face_file)\n","\n","    def __getitem__(self, idx):\n","        face_image = Image.open(self.face_path + '/' + self.face_file[idx])\n","        mask_image = Image.open(self.mask_path + '/' + self.mask_file[idx])\n","        face_image = self.transforms(face_image)\n","        mask_image = self.transforms(mask_image)\n","\n","        return (face_image,mask_image)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:03.596045Z","iopub.status.busy":"2021-12-18T16:58:03.595646Z","iopub.status.idle":"2021-12-18T16:58:04.26331Z","shell.execute_reply":"2021-12-18T16:58:04.262596Z","shell.execute_reply.started":"2021-12-18T16:58:03.596007Z"},"trusted":true},"outputs":[],"source":["train_dataset = FaceTrainDataset(face_path=face_path, mask_path=mask_path)\n","train_dataloader = DataLoader(train_dataset, batch_size=args.BATCH_SIZE)\n","test_dataset = FaceTestDataset(face_path=face_path, mask_path=mask_path)\n","test_dataloader = DataLoader(test_dataset, batch_size=args.BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:12.08877Z","iopub.status.busy":"2021-12-18T16:58:12.088516Z","iopub.status.idle":"2021-12-18T16:58:13.256277Z","shell.execute_reply":"2021-12-18T16:58:13.2546Z","shell.execute_reply.started":"2021-12-18T16:58:12.08874Z"},"trusted":true},"outputs":[],"source":["for i in range(len(train_dataset)):\n","    sample = train_dataset[i]\n","    ax = plt.subplot(1, 4, i + 1)\n","    plt.tight_layout()\n","    ax.set_title('Sample #{}'.format(i))\n","    ax.axis('off')\n","    if i % 2:\n","        sample_img = np.transpose(sample[0].cpu().detach().numpy(), (1,2,0))\n","    else:\n","        sample_img = np.transpose(sample[1].cpu().detach().numpy(), (1,2,0))\n","    plt.imshow(sample_img)\n","\n","    if i == 3:\n","        plt.show()\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:13.258487Z","iopub.status.busy":"2021-12-18T16:58:13.258017Z","iopub.status.idle":"2021-12-18T16:58:13.279084Z","shell.execute_reply":"2021-12-18T16:58:13.278318Z","shell.execute_reply.started":"2021-12-18T16:58:13.258449Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, bn=True):\n","            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, 0.8))\n","            return block\n","\n","        self.model = nn.Sequential(\n","            *discriminator_block(args.CHANNELS, 16, bn=False),\n","            *discriminator_block(16, 32),\n","            *discriminator_block(32, 64),\n","            *discriminator_block(64, 128),\n","        )\n","\n","        # The height and width of downsampled image\n","        ds_size = args.IMG_SIZE // 2 ** 4\n","        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, args.LATENT_DIM), nn.Sigmoid())\n","\n","    def forward(self, img):\n","        out = self.model(img)\n","        out = out.view(out.shape[0], -1)\n","        validity = self.adv_layer(out)\n","\n","        return validity\n","        \n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        \n","        self.encoder = Encoder().to(device)\n","        self.init_size = args.IMG_SIZE // 4\n","        self.l1 = nn.Sequential(nn.Linear(args.LATENT_DIM, 128 * self.init_size ** 2))\n","\n","        self.conv_blocks = nn.Sequential(\n","            nn.BatchNorm2d(128),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, args.CHANNELS, 3, stride=1, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        out = self.l1(z)\n","        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n","        img = self.conv_blocks(out)\n","        return img\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, bn=True):\n","            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, 0.8))\n","            return block\n","\n","        self.model = nn.Sequential(\n","            *discriminator_block(args.CHANNELS, 16, bn=False),\n","            *discriminator_block(16, 32),\n","            *discriminator_block(32, 64),\n","            *discriminator_block(64, 128),\n","        )\n","\n","        # The height and width of downsampled image\n","        ds_size = args.IMG_SIZE // 2 ** 4\n","        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n","\n","    def forward(self, img):\n","        out = self.model(img)\n","        out = out.view(out.shape[0], -1)\n","        validity = self.adv_layer(out)\n","\n","        return validity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:58:31.533848Z","iopub.status.busy":"2021-12-18T16:58:31.533397Z","iopub.status.idle":"2021-12-18T16:58:34.823684Z","shell.execute_reply":"2021-12-18T16:58:34.822831Z","shell.execute_reply.started":"2021-12-18T16:58:31.53381Z"},"trusted":true},"outputs":[],"source":["# Loss function\n","adversarial_loss = torch.nn.BCELoss().to(device)\n","mse_loss = torch.nn.MSELoss().to(device)\n","l1_loss = torch.nn.L1Loss().to(device)\n","\n","# Initialize generator and discriminator\n","generator = Generator().to(device)\n","discriminator = Discriminator().to(device)\n","\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=args.LR, betas=(args.B1, args.B2))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=args.LR, betas=(args.B1, args.B2))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to initialize weights\n","def _weights_init(m):\n","    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","    if isinstance(m, nn.BatchNorm2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","        torch.nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:03:03.520123Z","iopub.status.busy":"2021-12-16T05:03:03.519847Z","iopub.status.idle":"2021-12-16T05:03:03.534401Z","shell.execute_reply":"2021-12-16T05:03:03.533751Z","shell.execute_reply.started":"2021-12-16T05:03:03.52008Z"},"trusted":true},"outputs":[],"source":["# weight initialization\n","generator.apply(_weights_init)\n","discriminator.apply(_weights_init)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:03:03.535782Z","iopub.status.busy":"2021-12-16T05:03:03.535536Z","iopub.status.idle":"2021-12-16T05:03:03.540341Z","shell.execute_reply":"2021-12-16T05:03:03.53951Z","shell.execute_reply.started":"2021-12-16T05:03:03.535755Z"},"trusted":true},"outputs":[],"source":["os.makedirs('./saved_model')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:03:03.542559Z","iopub.status.busy":"2021-12-16T05:03:03.541971Z","iopub.status.idle":"2021-12-16T05:03:03.54787Z","shell.execute_reply":"2021-12-16T05:03:03.547087Z","shell.execute_reply.started":"2021-12-16T05:03:03.5425Z"},"trusted":true},"outputs":[],"source":["# Loss weight of L1 pixel-wise loss between translated image and real image\n","lambda_pixel = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:03:58.559107Z","iopub.status.busy":"2021-12-16T05:03:58.558767Z","iopub.status.idle":"2021-12-16T05:05:07.408639Z","shell.execute_reply":"2021-12-16T05:05:07.407522Z","shell.execute_reply.started":"2021-12-16T05:03:58.55907Z"},"trusted":true},"outputs":[],"source":["val_loss = []\n","train_loss = []\n","for epoch in range(args.EPOCHS):\n","    val_loss_=0\n","    train_loss_=0\n","    generator.train()\n","    discriminator.train()\n","    for i, (face_imgs, mask_imgs) in enumerate(train_dataloader):\n","        valid = Variable(Tensor(face_imgs.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n","        fake = Variable(Tensor(face_imgs.shape[0], 1).fill_(0.0), requires_grad=False).to(device)\n","        Y_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","        X_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","\n","        optimizer_G.zero_grad()\n","        gen_imgs = generator(X_imgs)\n","        g_loss = adversarial_loss(discriminator(gen_imgs), valid) + lambda_pixel*mse_loss(gen_imgs, Y_imgs)\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        optimizer_D.zero_grad()\n","        real_loss = adversarial_loss(discriminator(Y_imgs), valid)\n","        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","        \n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        train_loss_ += g_loss.item() + d_loss.item()\n","        print(\n","            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","            % (epoch, args.EPOCHS, i, len(train_dataloader), d_loss.item(), g_loss.item())\n","        )\n","        \n","        if i%20 == 0:\n","            ax = plt.subplot(2, 2, 1)\n","            plt.tight_layout()\n","            ax.set_title('Sample #{}'.format(i))\n","            ax.axis('off')\n","            sample_img = np.transpose(gen_imgs[0].cpu().detach().numpy(), (1,2,0))\n","            plt.imshow(sample_img)\n","\n","            ax = plt.subplot(2, 2, 2)\n","            plt.tight_layout()\n","            ax.set_title('Sample #{}'.format(i))\n","            ax.axis('off')\n","            sample_img = np.transpose(face_imgs[0].cpu().detach().numpy(), (1,2,0))\n","            plt.imshow(sample_img)\n","\n","            plt.show()\n","    \n","    train_loss_ /= len(train_dataloader)\n","    \n","    generator.eval()\n","    discriminator.eval()\n","    for i, (face_imgs, mask_imgs) in enumerate(test_dataloader):\n","\n","        Y_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","        X_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","\n","        gen_imgs = generator(X_imgs)\n","\n","        g_loss = adversarial_loss(discriminator(gen_imgs), valid) + lambda_pixel*mse_loss(gen_imgs, Y_imgs)\n","        real_loss = adversarial_loss(discriminator(Y_imgs), valid)\n","        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","        \n","        val_loss_ += g_loss.item() + d_loss.item()\n","        print(\n","            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","            % (epoch, args.EPOCHS, i, len(test_dataloader), d_loss.item(), g_loss.item())\n","        )\n","        \n","    val_loss_ /= len(test_dataloader)\n","\n","    train_loss.append(train_loss_)\n","    val_loss.append(val_loss_)\n","    \n","\n","torch.save(generator.state_dict(), \"./saved_model/dcgan_generator_lambda{}.pth\".format(lambda_pixel))\n","torch.save(discriminator.state_dict(), \"./saved_model/dcgan_discriminator_lambda{}.pth\".format(lambda_pixel))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loss weight of L1 pixel-wise loss between translated image and real image\n","lambda_pixel = 100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["val_loss = []\n","train_loss = []\n","for epoch in range(args.EPOCHS):\n","    val_loss_=0\n","    train_loss_=0\n","    generator.train()\n","    discriminator.train()\n","    for i, (face_imgs, mask_imgs) in enumerate(train_dataloader):\n","        valid = Variable(Tensor(face_imgs.shape[0], 1).fill_(1.0), requires_grad=False).to(device)\n","        fake = Variable(Tensor(face_imgs.shape[0], 1).fill_(0.0), requires_grad=False).to(device)\n","        Y_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","        X_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","\n","        optimizer_G.zero_grad()\n","        gen_imgs = generator(X_imgs)\n","        g_loss = adversarial_loss(discriminator(gen_imgs), valid) + lambda_pixel*mse_loss(gen_imgs, Y_imgs)\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        optimizer_D.zero_grad()\n","        real_loss = adversarial_loss(discriminator(Y_imgs), valid)\n","        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        train_loss_ += g_loss.item() + d_loss.item()\n","        print(\n","            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","            % (epoch, args.EPOCHS, i, len(train_dataloader), d_loss.item(), g_loss.item())\n","        )\n","        \n","        if i%20 == 0:\n","            ax = plt.subplot(2, 2, 1)\n","            plt.tight_layout()\n","            ax.set_title('Sample #{}'.format(i))\n","            ax.axis('off')\n","            sample_img = np.transpose(gen_imgs[0].cpu().detach().numpy(), (1,2,0))\n","            plt.imshow(sample_img)\n","\n","            ax = plt.subplot(2, 2, 2)\n","            plt.tight_layout()\n","            ax.set_title('Sample #{}'.format(i))\n","            ax.axis('off')\n","            sample_img = np.transpose(face_imgs[0].cpu().detach().numpy(), (1,2,0))\n","            plt.imshow(sample_img)\n","\n","            plt.show()\n","    \n","    train_loss_ /= len(train_dataloader)\n","    \n","    generator.eval()\n","    discriminator.eval()\n","    for i, (face_imgs, mask_imgs) in enumerate(test_dataloader):\n","        Y_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","        X_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","        \n","        gen_imgs = generator(X_imgs)\n","        g_loss = adversarial_loss(discriminator(gen_imgs), valid) + lambda_pixel*mse_loss(gen_imgs, Y_imgs)\n","        real_loss = adversarial_loss(discriminator(Y_imgs), valid)\n","        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","        \n","        val_loss_ += g_loss.item() + d_loss.item()\n","        print(\n","            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","            % (epoch, args.EPOCHS, i, len(test_dataloader), d_loss.item(), g_loss.item())\n","        )\n","        \n","    val_loss_ /= len(test_dataloader)\n","\n","    train_loss.append(train_loss_)\n","    val_loss.append(val_loss_)\n","    \n","\n","torch.save(generator.state_dict(), \"./saved_model/dcgan_generator_lambda{}.pth\".format(lambda_pixel))\n","torch.save(discriminator.state_dict(), \"./saved_model/dcgan_discriminator_lambda{}.pth\".format(lambda_pixel))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","loss_df = pd.DataFrame(data={'train_loss': train_loss, 'val_loss': val_loss})\n","loss_df.to_csv('./saved_model/dcgan_loss.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator.load_state_dict(torch.load('../input/dcgan-generator/dcgan_generator_lambda1.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:08:02.744045Z","iopub.status.busy":"2021-12-16T05:08:02.743427Z","iopub.status.idle":"2021-12-16T05:08:03.218996Z","shell.execute_reply":"2021-12-16T05:08:03.218293Z","shell.execute_reply.started":"2021-12-16T05:08:02.744005Z"},"trusted":true},"outputs":[],"source":["generator.eval()\n","sample = test_dataset[0]\n","ax = plt.subplot(1, 2, 1)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","mask_img = Variable(sample[1].type(Tensor)).to(device)\n","gen_img = generator(mask_img.unsqueeze(0))\n","sample_img = np.transpose(gen_img.cpu().detach().numpy().squeeze(0), (1,2,0))\n","plt.imshow(sample_img)\n","\n","ax = plt.subplot(1, 2, 2)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","sample_img = np.transpose(sample[0].cpu().detach().numpy(), (1,2,0))\n","plt.imshow(sample_img)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-16T05:08:10.01802Z","iopub.status.busy":"2021-12-16T05:08:10.017305Z","iopub.status.idle":"2021-12-16T05:08:10.470078Z","shell.execute_reply":"2021-12-16T05:08:10.469399Z","shell.execute_reply.started":"2021-12-16T05:08:10.017983Z"},"trusted":true},"outputs":[],"source":["generator.eval()\n","sample = test_dataset[1]\n","ax = plt.subplot(1, 2, 1)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","mask_img = Variable(sample[1].type(Tensor)).to(device)\n","gen_img = generator(mask_img.unsqueeze(0))\n","sample_img = np.transpose(gen_img.cpu().detach().numpy().squeeze(0), (1,2,0))\n","plt.imshow(sample_img)\n","\n","ax = plt.subplot(1, 2, 2)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","sample_img = np.transpose(sample[0].cpu().detach().numpy(), (1,2,0))\n","plt.imshow(sample_img)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T16:59:24.941533Z","iopub.status.busy":"2021-12-18T16:59:24.941042Z","iopub.status.idle":"2021-12-18T17:02:12.215218Z","shell.execute_reply":"2021-12-18T17:02:12.21445Z","shell.execute_reply.started":"2021-12-18T16:59:24.941489Z"},"trusted":true},"outputs":[],"source":["generator.eval()\n","l1_loss_value = 0\n","mse_loss_value = 0\n","for i, (face_imgs, mask_imgs) in enumerate(test_dataloader):\n","    face_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","    mask_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","    gen_imgs = generator(mask_imgs)\n","    l1_loss_value += l1_loss(gen_imgs, face_imgs).item()\n","    mse_loss_value += mse_loss(gen_imgs, face_imgs).item()\n","\n","l1_loss_value /= len(test_dataloader)\n","mse_loss_value /= len(test_dataloader)\n","print(\"Generator with lambda_pixel = 1\")\n","print(\"L1 loss: {}\".format(l1_loss_value))\n","print(\"MSE loss: {}\".format(mse_loss_value))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T17:02:12.217325Z","iopub.status.busy":"2021-12-18T17:02:12.216645Z","iopub.status.idle":"2021-12-18T17:02:14.491234Z","shell.execute_reply":"2021-12-18T17:02:14.490435Z","shell.execute_reply.started":"2021-12-18T17:02:12.217285Z"},"trusted":true},"outputs":[],"source":["generator.load_state_dict(torch.load('../input/dcgan-generator/dcgan_generator_lambda100.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator.eval()\n","sample = test_dataset[0]\n","ax = plt.subplot(1, 2, 1)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","mask_img = Variable(sample[1].type(Tensor)).to(device)\n","gen_img = generator(mask_img.unsqueeze(0))\n","sample_img = np.transpose(gen_img.cpu().detach().numpy().squeeze(0), (1,2,0))\n","plt.imshow(sample_img)\n","\n","ax = plt.subplot(1, 2, 2)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","sample_img = np.transpose(sample[0].cpu().detach().numpy(), (1,2,0))\n","plt.imshow(sample_img)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generator.eval()\n","sample = test_dataset[1]\n","ax = plt.subplot(1, 2, 1)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","mask_img = Variable(sample[1].type(Tensor)).to(device)\n","gen_img = generator(mask_img.unsqueeze(0))\n","sample_img = np.transpose(gen_img.cpu().detach().numpy().squeeze(0), (1,2,0))\n","plt.imshow(sample_img)\n","\n","ax = plt.subplot(1, 2, 2)\n","plt.tight_layout()\n","ax.set_title('Sample #{}'.format(i))\n","ax.axis('off')\n","sample_img = np.transpose(sample[0].cpu().detach().numpy(), (1,2,0))\n","plt.imshow(sample_img)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-18T17:02:14.492791Z","iopub.status.busy":"2021-12-18T17:02:14.492489Z","iopub.status.idle":"2021-12-18T17:04:00.477327Z","shell.execute_reply":"2021-12-18T17:04:00.476568Z","shell.execute_reply.started":"2021-12-18T17:02:14.49275Z"},"trusted":true},"outputs":[],"source":["generator.eval()\n","l1_loss_value = 0\n","mse_loss_value = 0\n","for i, (face_imgs, mask_imgs) in enumerate(test_dataloader):\n","    face_imgs = Variable(face_imgs.type(Tensor)).to(device)\n","    mask_imgs = Variable(mask_imgs.type(Tensor)).to(device)\n","    gen_imgs = generator(mask_imgs)\n","    l1_loss_value += l1_loss(gen_imgs, face_imgs).item()\n","    mse_loss_value += mse_loss(gen_imgs, face_imgs).item()\n","\n","l1_loss_value /= len(test_dataloader)\n","mse_loss_value /= len(test_dataloader)\n","print(\"Generator with lambda_pixel = 100\")\n","print(\"L1 loss: {}\".format(l1_loss_value))\n","print(\"MSE loss: {}\".format(mse_loss_value))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
